name: Big Data Processing

on:
    push:
      branches:
        - main

jobs:
  big_data_job:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repository
      - name: Checkout code
        uses: actions/checkout@v3

      # Step 2: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas dask

      # Step 4: Download the dataset
      - name: Download dataset
        run: |
          cd Python/big_data
          curl -o routes.dat https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat

      # Step 5: Run the Python script for big data processing
      - name: Run big data processing script
        run: |
          cd Python/big_data
          python big_data_processing.py

    # # Step : Run the Spotify script
    #   - name: Run big data processing script
    #     run: |
    #       cd Python
    #       pip install spotipy
    #       python spotify_.py

      # Step 6: Upload the artifact to GitHub
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: output-file
          path: Python/big_data/processed_data.csv